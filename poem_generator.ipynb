{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bad Poets Society\n",
    "## Computational Creativity 2021 - Assignemnt 2\n",
    "\n",
    "Emilio Sanchez Olivares & Saket Narendra "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Markov Chains\n",
    "\n",
    "This assignment aims to implement a poem generator using techniques covered in the lectures. One of such techniques are Markov Chains, which are implemented below[^1]. This is a very simple first approach, and we aim to use it as a baseline.\n",
    "\n",
    "\n",
    "[^1]: https://medium.com/upperlinecode/making-a-markov-chain-poem-generator-in-python-4903d0586957"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Longer axis, and\\nWith no dream it was any haunt of all around the cold accumulation of the labour knows.\\nMy long after enumerating\\nthe most preserved is no pain,\\nStill wouldst thou didst ever you lived, but a quotation. In the stars follows Light blue and another, why is not, and kept his pipe-stem, saying,\\n\"You can see the surface that which in everything. May in the Heart\\'s desire.\\'\\nAnne has that necessity\\nis a straight face.\" \"If you wished you do not blaming there is there is not travel both\\nAnd be that ministering counting. It was in her subtle fluid in a winter he come'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "poems = open(\"inspiring_poems.txt\", \"r\").read()\n",
    "poems = ''.join([i for i in poems if not i.isdigit()]).replace(\"\\n\\n\", \" \").split(' ')\n",
    "# This process the list of poems. Double line breaks separate poems, so they are removed.\n",
    "# Splitting along spaces creates a list of all words.\n",
    "\n",
    "index = 1\n",
    "chain = {}\n",
    "count = 100 # Desired word count of output\n",
    "\n",
    "# This loop creates a dicitonary called \"chain\". Each key is a word, and the value of each key \n",
    "# is an array of the words that immediately followed it.\n",
    "for word in poems[index:]: \n",
    "\tkey = poems[index - 1]\n",
    "\tif key in chain:\n",
    "\t\tchain[key].append(word)\n",
    "\telse:\n",
    "\t\tchain[key] = [word]\n",
    "\tindex += 1\n",
    "\n",
    "word1 = random.choice(list(chain.keys())) #random first word\n",
    "message = word1.capitalize()\n",
    "\n",
    "# Picks the next word over and over until word count achieved\n",
    "while len(message.split(' ')) < count:\n",
    "\tword2 = random.choice(chain[word1])\n",
    "\tword1 = word2\n",
    "\tmessage += ' ' + word2\n",
    "\n",
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markovify\n",
    "\n",
    "To improve the simple implementation, we use the `markovify` Python package which builds Markov models of large corpora of text and generating random sentences from that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first `markovify` approach generates 10 random lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Room to comb chickens and feathers and ripe plates and large sets and second silver, room to save heat and distemper, room to curve single plates and little ways.\n",
      "I threw my shell away upon the soft bombs of dust It bursts against us at the set of sisters and an established cork and blazing, this which was left For him to his heart he inwardly did pray For power to speak; but still slept.\n",
      "IÃ¤petus another; in his college.\n",
      "the morning upon the muffling dark Sweet-shaped lightnings from the way I might best Give consolation in this little earth, drowns the silence of the sea, the noise of these nights.\n",
      "They realised from the way I was, He told me afterward.\n",
      "Suppose it is not sad is blue as every bit of it, which isn't much.\n",
      "No eye-glasses are rotten, no window is useless and yet has visible writing, this is not such a piteous theme.\n",
      "Is it dainty, it is little please.\n",
      "What did he come in there not be in the right place for love: I don't know how glad I was like to change, supposing it is there plenty of room for it.\n",
      "Excellent not a cover and the chain, cut the grass, silence the aching secret of love?\n"
     ]
    }
   ],
   "source": [
    "with open(\"inspiring_poems.txt\") as f:\n",
    "    text = f.read()\n",
    "    \n",
    "text_model = markovify.Text(text)\n",
    "\n",
    "for i in range(10):\n",
    "    print(text_model.make_sentence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package does a good job in generating sentences. However, they tend to be quite long. While the package itself has a method to limit the number of characters, we set to implement a function that counts the syllables to make the generated text more poem-like. A repository[^2] attempted to do this for rap songs, and we adapt this to poems.\n",
    "\n",
    "[^2]: https://github.com/robbiebarrat/rapping-neural-network/blob/master/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that creates a markov model of a text\n",
    "\n",
    "def markov(text_file):\n",
    "\tread = open(text_file, \"r\", encoding='utf-8').read()\n",
    "\ttext_model = markovify.NewlineText(read)\n",
    "\treturn text_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that makes sure the line doesn't exceed a defined number of syllables\n",
    "\n",
    "def syllables(line):\n",
    "\tcount = 0\n",
    "\tfor word in line.split(\" \"):\n",
    "\t\tvowels = 'aeiouy'\n",
    "\t\tword = word.lower().strip(\".:;?!\")\n",
    "\t\tif word[0] in vowels:\n",
    "\t\t\t# a vowel found at the begining of the word makes a syllable\n",
    "\t\t\tcount +=1\n",
    "\t\tfor index in range(1,len(word)):\n",
    "\t\t\t# a non-vowel followed by a vowel makes a syllable\n",
    "\t\t\tif word[index] in vowels and word[index-1] not in vowels:\n",
    "\t\t\t\tcount +=1\n",
    "\t\tif word.endswith('e'):\n",
    "\t\t\t# if word ends in (silent) 'e', that is not a syllable\n",
    "\t\t\tcount -= 1\n",
    "\t\tif word.endswith('le'):\n",
    "\t\t\t# unless 'le'\n",
    "\t\t\tcount+=1\n",
    "\t\tif count == 0:\n",
    "\t\t\tcount +=1\n",
    "\treturn count / maxsyllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = 'inspiring_poems.txt' # read training dataset\n",
    "bars = [] # initialise poem as list of lines\n",
    "last_words = [] # initialise last words of each line\n",
    "poem_length = len(open(text_file,encoding='utf-8').read().split(\"\\n\")) # poem length\n",
    "\t# we won't use this because we read a collection of poems\n",
    "count = 0 #initialise count of lines\n",
    "markov_model = markov(text_file) # markov model using training data\n",
    "maxsyllables = 8 # set limit of syllables per line\n",
    "\t\n",
    "\t\n",
    "\n",
    "#while len(bars) < poem_length / 9 and count < poem_length * 2:\n",
    "while len(bars) < 10 and count < poem_length * 2:\n",
    "\t\tbar = markov_model.make_sentence(max_overlap_ratio = .49, tries=100)\n",
    "\t\tif type(bar) != type(None) and syllables(bar) < 1:\n",
    "\t\t\tdef get_last_word(bar):\n",
    "\t\t\t\tlast_word = bar.split(\" \")[-1]\n",
    "\t\t\t\tif last_word[-1] in \"!.?,\":\n",
    "\t\t\t\t\tlast_word = last_word[:-1]\n",
    "\t\t\t\treturn last_word\n",
    "\t\t\tlast_word = get_last_word(bar)\n",
    "\t\t\tif bar not in bars and last_words.count(last_word) < 3:\n",
    "\t\t\t\tbars.append(bar)\n",
    "\t\t\t\tlast_words.append(last_word)\n",
    "\t\t\t\tcount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ah! what if I could put a tree',\n",
       " 'But he thought that I had drunk,',\n",
       " 'in the way with the depth of truth.',\n",
       " 'Let not the one who takes',\n",
       " 'Where is the one less to say,',\n",
       " 'And still the bird in the pearly seas,',\n",
       " 'Shut from the moon, the sun, like a',\n",
       " 'Toes are the light the fire.',\n",
       " 'My voice is the fountain of',\n",
       " 'make the time that is simpler,']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `markovify ` package, with aid of the syllable counter function do a better job in generating poem-like texts. This can actually be seen as an actual poem. The words look meaningless at first, but there is potential to interpret at a metaphorical level."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "886053000daa245de5471dbd3794bd25fab03043c144a2305c32edfd01785e47"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('env2': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
